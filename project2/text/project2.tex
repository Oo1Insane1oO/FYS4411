\documentclass[a4paper, hidelinks, 10pt]{article}
\usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}
% \usepackage{libertine}
% \usepackage[libertine]{newtxmath}
\usepackage{charter}
\usepackage[expert, charter]{mathdesign}
\usepackage{listings}
\usepackage[pdftex]{graphicx}
\usepackage{color}
\usepackage{mathtools}
% \usepackage{amssymb}
\usepackage[margin=0.7in]{geometry}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{float}
\usepackage{caption}
\usepackage{scrextend}
\usepackage{ragged2e}
\usepackage{multirow}
\usepackage{array}
\usepackage{physics}
\usepackage{enumitem}
\usepackage{varwidth}
\usepackage{tikz}
\usepackage{etoolbox}
\usepackage{fancyhdr}
\usepackage{dsfont}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xifthen}

%specific reused text
\newcommand{\mdate}{\today}
\newcommand{\mtitle}{FYS4411}
\newcommand{\mauthor}{Alfred Alocias Mariadason}
\newcommand{\massignn}{Project 2}

\pagestyle{fancy}
\fancyhf{}
% \fancyhead[LO, RE]{\small\leftmark}
\lhead{\small{\mtitle}}
\chead{\small{\massignn}}
\rhead{\small{\thesection}}
% \lfoot{}
\cfoot{\thepage}
% \rfoot{}

\patchcmd{\thebibliography}{\section*}{\section}{}{}

%renew title numbering
\renewcommand{\thesection}{\Roman{section}}
\renewcommand{\thesubsection}{\thesection.\Alph{subsection}}

%center title and subtitle
\let\oldsection\section
\renewcommand{\section}[1]{\centering \oldsection{{#1}} \justifying}
\let\oldsubsection\subsection
\renewcommand{\subsection}[1]{\centering \oldsubsection{{#1}} \justifying}

%set counter for algorithm
\newcommand{\algorithmautorefname}{algorithm}

%title settings
% \renewcommand{\headrulewidth}{0pt}
\renewcommand{\sectionautorefname}{section}
\renewcommand{\subsectionautorefname}{section}
\renewcommand{\subsubsectionautorefname}{section}
\renewcommand{\equationautorefname}{equation}
\renewcommand{\figureautorefname}{figure}
\renewcommand{\tableautorefname}{table}
\captionsetup{compatibility=false}

\patchcmd{\smallmatrix}{\thickspace}{\kern1.3em}{}{}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.3,0.3,0.3}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
        backgroundcolor=\color{backcolour},
        commentstyle=\color{codegreen},
        keywordstyle=\color{magenta},
        numberstyle=\tiny\color{codegray},
        stringstyle=\color{codepurple},
        basicstyle=\footnotesize,
        breakatwhitespace=false,
        breaklines=true,
        captionpos=b,
        keepspaces=true,
        numbers=left, 
        numbersep=4pt, 
        showspaces=false, 
        showstringspaces=false,
        showtabs=true, 
        tabsize=2
}
\lstset{style=mystyle}

\hypersetup{
    allcolors=black
}
\urlstyle{same}

\newcommand{\onefigure}[4]{
    \begin{figure}[H]
        \centering
        \textbf{{#1}}\\
        \includegraphics[scale=0.65]{{#2}}
        \caption{{#3}}
        \label{fig:#4}
    \end{figure}
    \justifying
} %one figure {filename}{caption}
\newcommand{\twofigure}[7]{
    \begin{figure}[H]
        \centering
        \begin{subfigure}[b!]{0.49\textwidth}
            \centering
            \includegraphics[width=\textwidth]{{#1}}
            \caption{{#2}}
            \label{subfig:#3}
        \end{subfigure}
        \begin{subfigure}[b!]{0.49\textwidth}
            \centering
            \includegraphics[width=\textwidth]{{#4}}
            \caption{{#5}}
            \label{subfig:#6}
        \end{subfigure}
        \caption{#7}
        \justify
    \end{figure}
} %two figure one-line {title}{file1}{caption1}{file2}{caption2}


\newcommand{\prtl}{\mathrm{\partial}} %reduce length of partial (less to write)
% \newcommand{\prd}[3]{\frac{\prtl^{#3}#1}{\prtl {#2}^{#3}}} %partial derivative specific
% \newcommand{\prds}[2]{\frac{\prtl #1}{\prtl {#2}}} % partial derivative general
% \newcommand{\fprds}[1]{\frac{\prtl}{\prtl {#1}}} %reduce length of partial (less to write)
% \newcommand{\fprd}[2]{\frac{\prtl^{#2}}{\prtl^{#2} {#1}}} %reduce length of partial (less to write)

\newcommand{\prd}[2]{\ifthenelse{\isempty{#2}}{\frac{\prtl^{#2}}{\prtl{#1}^{#2}}}{\frac{\prtl}{\prtl{#1}}}}
\newcommand{\fprd}[3]{\ifthenelse{\isempty{#3}}{\frac{\prtl^{#3}{#1}}{\prtl{#2}^{#3}}}{\frac{\prtl#1}{\prtl#2}}}

\newcommand{\vsp}{\vspace{0.2cm}} %small vertical space
\newcommand{\txtit}[1]{\textit{{#1}}} %italic text
\newcommand{\blds}[1]{\boldsymbol{{#1}}} % better bold in mathmode (from amsmath)
\newcommand{\bigO}{\mathcal{O}} %nice big O
\newcommand{\me}{\mathrm{e}} %straight e for exp
\newcommand{\md}{\mathrm{d}} %straight d for differential
\newcommand{\mRe}[1]{\mathrm{Re}\left({#1}\right)}%nice real
\newcommand{\munit}[1]{\;\ensuremath{\, \mathrm{#1}}} %straight units in math
\newcommand{\Rarr}{\Rightarrow} %reduce lenght of Rightarrow (less to write)
\newcommand{\rarr}{\rightarrow} %reduce lenght of rightarrow (less to write)
\newcommand{\ecp}[1]{\left< {#1} \right>} %expected value
\newcommand{\urw}{\uparrow} % up arrow
\newcommand{\drw}{\downarrow} % up arrow
\newcommand{\pt}[1]{\textbf{\txtit{#1}}\justify}
\newcommand{\infint}{\int\limits^{\infty}_{-\infty}}
\newcommand{\oinfint}{\int\limits^{\infty}_0}
\newcommand{\sint}{\int\limits^{2\pi}_0\int\limits^{\pi}_0\oinfint}
\newcommand{\arcsinh}[1]{\text{arcsinh}\left(#1\right)}
\newcommand{\I}{\scalebox{1.2}{$\mathds{1}$}}
\newcommand{\veps}{\varepsilon} %\varepsilon is to long :P

\newcommand{\fij}[3]{#1\left(#2\rarr#3\right)}
\newcommand{\ufij}[3]{#1_{#2\rarr#3}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\newcommand{\infoTabs}[2]{
    \begin{tabular}{crl}
        \multicolumn{3}{c}{\textbf{$\blds{N=#1}$}} \\
        \multicolumn{1}{c}{$R$} & \multicolumn{1}{c}{$E_0[au]$} &
        \multicolumn{1}{c}{$I$} \\
        \hline
        \input{#2}
    \end{tabular}
}

\newcommand{\infoTables}[7]{
    \begin{table}[H]
        \centering
        \textbf{Energies with $\blds{\omega=#1}$} \\
        \hrule \vspace{1.5pt} \hrule \vspace{0.7pt}
        \infoTabs{2}{#2}
        \infoTabs{6}{#3}
        \infoTabs{12}{#4}
        \infoTabs{20}{#5}
        \hrule \vspace{1.5pt} \hrule \vspace{0.7pt}
        \caption{#6}
        \justifying
        \label{tab:#7}
    \end{table}
}

\makeatletter
% define a macro \Autoref to allow multiple references to be passed to \autoref
\newcommand\Autoref[1]{\@first@ref#1,@}
\def\@throw@dot#1.#2@{#1}% discard everything after the dot
\def\@set@refname#1{%    % set \@refname to autoefname+s using \getrefbykeydefault
    \edef\@tmp{\getrefbykeydefault{#1}{anchor}{}}%
    \def\@refname{\@nameuse{\expandafter\@throw@dot\@tmp.@autorefname}s}%
}
\def\@first@ref#1,#2{%
  \ifx#2@\autoref{#1}\let\@nextref\@gobble% only one ref, revert to normal \autoref
  \else%
    \@set@refname{#1}%  set \@refname to autoref name
    \@refname~\ref{#1}% add autoefname and first reference
    \let\@nextref\@next@ref% push processing to \@next@ref
  \fi%
  \@nextref#2%
}
\def\@next@ref#1,#2{%
   \ifx#2@ and~\ref{#1}\let\@nextref\@gobble% at end: print and+\ref and stop
   \else, \ref{#1}% print  ,+\ref and continue
   \fi%
   \@nextref#2%
}
\makeatother

\begin{document}
\thispagestyle{empty}
\begin{center} \vspace{1cm}
    \textbf{\Large{\mtitle\hspace{0.01pt} - Computational Physics II: Quantum
    Mechanical Systems}}\\ \vspace{0.5cm}
    \textbf{\large{\massignn\hspace{0.01pt} - Variatonal Monte Carlo
    Methods}}\\ \vspace{1cm}
    \textbf{\large{\mauthor}}\\ \vspace{0.5cm}
    \large{\url{https://www.github.com/Oo1Insane1oO/FYS4411}} \\ \vspace{0.5cm}
    \Large{\mdate}\\ \vfill
\end{center}

\clearpage
\setcounter{page}{1}

\begin{center}
    \textbf{Abstract} \\
\end{center}

\section{INTRODUCTION}
\label{sec:introduction}
    Using the Variational Monte Carlo, this project aims to find and analyze
    quantities such as the ground state energy and single-particle densities of
    quantum dots for so-called closed shell systems.

    We use the usual approach by estimating expectation value of the ground
    state energy with the variational principle and minimizing. The algorithm
    used for the Monte Carlo method is the well known Metropolis algorithm.

    The reason for using a Monte Carlo method for minimizing the trial ground
    state energy is because the expectation value would in general be a
    multi-dimensional integral depending on the number of particles and number
    of parameters involved in the total wave function. Such an integral is not
    adequately solved by traditional methods(i.e Gaussian-quadrature).

    The desired result is that the Metropolis algorithm with importance
    sampling yields a better result both from a computational point of view.
    That is it finds a good estimate for the ground state energy efficiently
    without wasting to much time on the configuration space. The wave function
    only has small values in this large space meaning a homogeneous
    distribution of calculation points would yield a poor result, a
    non-homogeneous approach(such as with the Metropolis algorithm) would then,
    hopefully, gives a better result.

\section{THEORY}
\label{sec:theory}
    >>INSERT DESCRIPTION<<

\subsection{HERMITE POLYNOMIALS}
\label{sub:hermite_polynomials}
    Hermite polynomials $H(x)$ are solutions to the differential equation
        \begin{equation}
            \frac{\md^2 H}{\md x^2} -2x\frac{\md H}{\md x} + \left(\lambda
            -1\right)H = 0
            \label{eq:hermitediffeq}
        \end{equation}
    The polynomials fulfill the orthogonality relation 
        \begin{equation}
            \infint \me^{-x^2}H^2_n\md x = 2^nn!\sqrt{\pi}
            \label{eq:hermiteOrth}
        \end{equation}
    with the recurrence relation
        \begin{equation}
            H_{n+1} = H_n - 2nH_{n-1}
            \label{eq:hermiteReq}
        \end{equation}

\subsection{HARMONIC OSCILLATOR}
\label{sub:harmonic_oscillator}
\subsubsection{Cartesian Coordinates}
\label{ssub:Cartesian Coordinates}
    The harmonic oscillator system in $2$ dimensions and in natural units is
    given by the following Hamiltonian
        \begin{equation}
            \hat{H_0} = \frac{1}{2}\sum^N_{i=1}\left(-\nabla^2_i + \omega^2
            r^2_i\right)
            \label{eq:cartHarmOsc}
        \end{equation}
    The wave functions in this case is then:
        \begin{equation}
            \phi_{n_x,n_y}(x,y) =
            AH_{n_x}(\sqrt{\omega}x)H_{n_y}(\sqrt{\omega}y)
            \exp(-\frac{\omega}{2}(x^2+y^2))
            \label{eq:cartUarmOscWavef}
        \end{equation}
    where $H_n$ is a hermite polynomial of order $n$ and $A$ is a normalization
    constant. The quantum numbers $n_x$ and $n_y$ go as $n_x,n_y=0,1,2\dots$.
    While $\omega$ is the oscillator frequency. \\
    The energies is 
        \begin{equation}
            E = \hbar\omega\left(n_x + n_y + 1\right)
            \label{eq:cartHarmOscE}
        \end{equation}

\subsection{METROPOLIS-HASTINGS ALGORITHM}
\label{sub:metropolis_algorithm}
    The Metropolis algorithm bases itself on moves (also called transitions) as
    given in a Markov process(or Markov chain). Define a probability
    distribution function(PDF) $w_j(t)$ with a transition probability
    $\fij{w}{i}{j}$ which for a given time-step yields in the Markov formula
        \begin{equation}
            w_i(t+\veps) = \sum\limits_j \fij{w}{j}{i} w_j(t)
            \label{eq:MarkovFormula}
        \end{equation}
    The transition probability is defined with an acceptance probability
    distribution $\fij{A}{j}{i}$ and a proposed probability distribution
    $\fij{T}{j}{i}$ as
        \begin{equation}
            \fij{w}{j}{i} = \fij{A}{j}{i}\fij{T}{j}{i}
            \label{eq:wijdef}
        \end{equation}
    The acceptance $A$ is the probability for the move to be accepted and the
    proposal $T$ is different for each problem. \\
    In order for this transition chain to reach a desired convergence and
    reversibility we have the well known condition for detailed balance
    >>INSERT REF<<. This condition gives us that the probability distribution
    functions satisfy the following condition
        \begin{equation}
            w_i \ufij{T}{i}{j}\ufij{A}{i}{j} = w_j \ufij{T}{j}{i}\ufij{A}{j}{i}
            \Rarr \frac{w_i}{w_j} =
            \frac{\ufij{T}{j}{i}\ufij{A}{j}{i}}{\ufij{T}{i}{j}\ufij{A}{i}{j}}
            \label{eq:detailedBalance}
        \end{equation}
    We now need to choose an acceptance which fulfills
    \Autoref{eq:detailedBalance} and a common choice is the Metropolis
    condition
        \begin{equation}
            \ufij{A}{j}{i} = \min\left(1,
            \frac{w_i\ufij{T}{i}{j}}{w_j\ufij{T}{j}{i}}\right)
            \label{eq:MetropolisCondition}
        \end{equation}
    The Metropolis-Hastings algorithm is thus
        \begin{enumerate}[label=(\roman*)]
            \item Pick initial state $i$ at random.
            \item Pick proposed state at random in accordance to
                $\ufij{T}{j}{i}$.
            \item Accept state according to $\ufij{A}{j}{i}$.
            \item Jump to step (ii) until a specified number of states have
                been generated.
            \item Save the state $i$ and jump to step (ii).
        \end{enumerate}

\subsection{VARIATIONAL PRINCIPLE}
\label{sub:variational_principle}
    The variational principle states the following restriction on the ground
    state energy for a given symmetry
        \begin{equation}
            E_0 \leq \ecp{E[\Phi_T]} = \int \phi^{*}_T\hat{H}\phi_T\md\tau =
            \bra{\phi_T}\hat{H}\ket{\phi_T}
            \label{eq:HFvarE}
        \end{equation}
    that is the ground state energy $E_0$ is bounded by the expectation value
    of the trial energy.

\subsection{IMPORTANCE SAMPLING}
\label{sub:importance_sampling}
    In order to use the Metropolis algorithm as explained in
    \Autoref{sub:metropolis_algorithm}, we need to find the proposal
    probability distribution labeled $\ufij{T}{j}{i}$. This is what is known as
    importance sampling. \\
    This section will derive the importance sampling by using the Fokker-Planck
    equation for one particle
        \begin{equation}
            \fprd{P}{t} = D\prd{x} (\prd{x} - F)P(x,t)
            \label{eq:FokkerPlanc}
        \end{equation}
%     where $F$ is a drift term and $D$ is a diffusion constant, and the Langevin
%     equation
%         \begin{equation}
%             \prds{x(t)}{t} = DF(x(t)) + \eta
%         \end{equation}
%     where $\eta$ is a random variable. \\
%     Since we are working with a isotropic diffusion characterized by a
%     time-dependant probability density our system must obey the summed total
%     Fokker-Planck equation
%         \begin{equation}
%             \prds{P}{t} = \sum\limits_iD\fprd{x_i}\left(\fprd{x_i} -
%             F_i\right)P(x,t)
%             \label{eq:FokkerPlancTotal}
%         \end{equation}
%     where $F_i$ is now the i'th component of the drift velocity term(given by
%     an external potential). Since the probability is assumed to be convergent,
%     that is it converges to a stationary probability density the time
%     dependence at this point is zero. With other words, the left hand side of
%     \Autoref{eq:FokkerPlancTotal} is zero we we obtain
%         \begin{equation}
%             \fprds{P}{x_i}{2} = 
%         \end{equation}
% 
\subsubsection{Quantum Force}
\label{ssub:Quantum Force}
    We rewrite the Fokker-Planc equation(\Autoref{eq:FokkerPlanc}) 


\subsection{VMC}
\label{sub:vmc}
    This section will explain and derive the equations involved in the
    Variational Monte Carlo method. The whole section will assume that we have
    the following trial wave function, $\psi_T$
        \begin{equation}
            \psi_T(\vec{r}_1,\dots,\vec{r}_N) \equiv
            \det(\phi_1(\vec{r}_1,\alpha),\dots,\phi(\vec{r}_N,\alpha))
            \prod^N_{i<j} \exp(\frac{ar_{ij}}{1+\beta r_{ij}})
            \label{eq:psiT}
        \end{equation}
    with the $\vec{r}$'s being the position of the electrons and the $\phi$'s
    being the wave function to some known system(i.e harmonic oscillator). The
    position $r_{ij}$ is a relative distance $\abs{\vec{r}_i-\vec{r}_j}$ while
    $\alpha$ and $\beta$ are variational parameters and $a$ is a specific
    constant dependant of the total spin symmetry of electron $i$ and $j$ as
        \begin{equation}
            a = \left\{
                    \begin{aligned}
                        1, & \indent \text{anti-parallel spin} \\
                        \frac{1}{3}, & \indent \text{parallel spin}
                    \end{aligned}
                \right.
            \label{eq:a}
        \end{equation}
    This is also known as a $Pade-Jatrow$ factor. \\
    We also define the total Hamiltonian of the system for the quantum dot case
    as
        \begin{equation}
            \hat{H} = \hat{H}_O + \hat{H}_I
            \label{eq:totalHamil}
        \end{equation}
    with $\hat{H}_O$ being the harmonic oscillator defined in
    \Autoref{eq:cartHarmOsc} and $\hat{H}_I$ being the Hamiltonian for the
    electron interactions(Coulomb interaction) defined as
        \begin{equation}
            \hat{H}_I = \sum_{i<j}\frac{1}{r_{ij}}
            \label{eq:hamilCou}
        \end{equation}
    Lastly, we work in natural units setting $\hbar=c=1$, and all the above
    equations(\Autoref{eq:psiT,eq:a,eq:totalHamil,eq:hamilCou}) also assume
    natural units.

\subsubsection{Expectation Value and Local Energy}
\label{ssub:EXPECTATION VALUE AND LOCAL ENERGY}
    Given the Hamiltonian \Autoref{eq:totalHamil} and a trial wave function
    $\Psi_T(R,\Lambda)$ and using the variational principle, as given in
    \Autoref{eq:HFvarE} the upper bound for the ground state energy $E_0$ if
    $H(r)$ is
        \begin{equation}
            E[\hat{H}(R,\Lambda)] \leq \ecp{\hat{H}} =
            \frac{\bra{\Psi_T}\hat{H}\ket{\Psi_T}}{\braket{\Psi_T}}
            \label{eq:HupperBound}
        \end{equation}
    where $R=(r_1,\dots,r_N)$ is the positions to $N$ particles and
    $\Lambda=(\lambda,\dots,\lambda_M)$ are the $M$ variational parameters. \\
    Now we can expand the trial wave function $\Psi_T(R,\Lambda)$ in the
    orthonormal eigenstates of the Hamiltonian $\hat{H}$(which form a complete
    set)
        \begin{equation}
            \Psi_T(r) = \sum_ic_i\Psi_i(r)
            \label{eq:PsiTExpand}
        \end{equation}
    and the upper bound given in \Autoref{eq:HupperBound} is
        \begin{equation}
            E_0 \leq \frac{\sum\limits_{ij}c_ic^{*}_j
            \bra{\Psi_j}\hat{H}\ket{\Psi_i}} {\sum\limits_{ij}c_ic^{*}_j
            \bra{\Psi_j}\ket{\Psi_i}} = \frac{\sum\limits_n
            a^2_nE_n}{\sum\limits_n a^2_n}
            \label{eq:HupperBoundExpand}
        \end{equation}
    where the eigenequation for the Hamiltonian $\hat{H}\Psi_n=E_n\Psi_n$ was
    used. The expression given in \Autoref{eq:HupperBound} is the expectation
    value we evaluate in each variational step that is we choose $\alpha$
    according to some minimization algorithm and re-evaluate the expectation
    value. \\
    In order to introduce the transition probability as given in the Metropolis
    algorithm(see \Autoref{sub:metropolis_algorithm}) the expectation value,
    \Autoref{eq:HupperBoundExpand}, needs to be rewritten in terms of a PDF. We
    can define this as
        \begin{equation}
            P(R) \equiv \frac{\abs{\Psi_T(R)}^2}{\int\abs{\Psi_T(R)}^2\md R}
            \label{eq:PDFdef}
        \end{equation}
    Now we observe that if we define a quantity
        \begin{equation}
            E_L(R,\Lambda) \equiv
            \frac{1}{\Psi_T(R,\Lambda)}\hat{H}\Psi_T(R,\Lambda)
            \label{eq:ELdef}
        \end{equation}
    which is the so-called local energy. The expectation value given in
    \Autoref{eq:HupperBoundExpand} can be rewritten as
        \begin{equation}
            E[H] = \int P(R)E_L(R\Lambda) \md R \approx
            \frac{1}{N}\sum\limits_{i=1}^N P(r_i,\Lambda)E_L(r_i,\Lambda)
            \label{eq:ecpRew}
        \end{equation}
    which is of the form given in \Autoref{eq:MarkovFormula} and $N$ is the
    number of states(or Monte Carlo cycles).

\subsubsection{Analytical Expression for Local Energy}
\label{ssub:ANALYTICAL EXPRESSION FOR LOCAL ENERGY}
    We use the Metropolis algorithm to find an estimate for the expectation
    value to the energy. In this expression we have a so-called local energy
    defined as
        \begin{equation}
            E_L = \frac{1}{\psi_T}\hat{H}\psi_T
            \label{eq:ELana}
        \end{equation}
    This expression shows up in the integrand as the multiplied function to the
    PDF which is used in the Metropolis algorithm.

\subsubsection{Two Electron Case}
\label{ssub:Two Electron Case}
    We start by finding the local energy in the case with two electrons. The
    trial wave function is in this case(related to
    \Autoref{eq:cartUarmOscWavef}) using \Autoref{eq:psiT}
        \begin{equation}
            \psi_T(\vec{r}_1,\vec{r_2}) =
            A\exp(-\frac{\alpha\omega}{2}\left(r^2_1+r^2_2\right))
            \exp(\frac{ar_{12}}{1+\beta r_{12}})
            \label{eq:TECpsiT}
        \end{equation}
    Using the definition of the trial wave function, \Autoref{eq:ELdef} and the
    total Hamiltonian(\Autoref{eq:totalHamil}) the local energy with
    \Autoref{eq:ELdef} is
        \begin{equation}
            E_L = \frac{1}{\psi_T}\left(\hat{H}_O\psi_T +
            \hat{H}_I\psi_T\right)
            \label{eq:EL2}
        \end{equation}
    we solve the first part $\hat{H}_O\psi_T$
        \begin{equation}
            \hat{H}_O\psi_T = \frac{1}{2}\left(-\nabla^2_1 - \nabla^2_2 +
            \omega^2\left(r^2_1 + r^2_2\right)\right)\psi_T
            \label{eq:locF}
        \end{equation}
    Starting with the Laplacian for electron $1$
        \begin{equation}
            \nabla^2_1\psi_T = \frac{\md^2\psi_T}{\md x^2_1} +
            \frac{\md^2\psi_T}{\md y^2_1}
            \label{eq:locFF}
        \end{equation}
    The first differential is
        \begin{equation}
            \frac{\md^2\psi_T}{\md x^2_1} = A\exp(-\frac{\alpha\omega}{2}r^2_2)
            \exp(-\frac{\alpha\omega}{2}y^2_1) \frac{\md^2}{\md x^2_1}\left[
                \exp(-\frac{\alpha\omega}{2}x^2_1) \exp(\frac{ar_{12}}{1+\beta
                r_{12}})\right]
        \end{equation}
    using the product rule for differentiation we get
        \begin{equation}
            \frac{\md^2}{\md x^2_1}\left[\exp(-\frac{\alpha\omega}{2}x^2_1)
            \exp(\frac{ar_{12}}{1+\beta r_{12}})\right] = \frac{\md}{\md x}\left[\exp(\frac{ar_{12}}{1+\beta r_{12}})\frac{\md}{\md x}\exp(-\frac{\alpha\omega}{2}x^2_1) + \exp(-\frac{\alpha\omega}{2}x^2_1) \frac{\md}{\md x}\exp(\frac{ar_{12}}{1+\beta r_{12}})\right]
        \end{equation}
%             r_{12} = \sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}

%         \begin{align*}
%             \input{analyticEL2AllCollect.tex}
%         \end{align*}
    
%     Before we arrive at the final expression for the expectation value(which
%     the Metropolis algorithm will be applied on) we start by defining a trial
%     wave function $\psi_T$ as
%         \begin{equation}
%             \psi_T(\vec{r}_1,\dots,\vec{r}_N;\alpha_1,\dots)
%         \end{equation}
%     where the $r$'s are the position for the individual particles and the
%     $\alpha$'s are variational parameters, and use the variational principle to
%     arrive at
%         \begin{equation}
%             E_0 \leq \ecp{E(\alpha_1,\dots)} =
%             \frac{\int\psi^{*}_T\hat{H}\psi_T\md^N\vec{r}}
%             {\abs{\psi_T}^2\md^N\vec{r}}
%             \label{eq:vmcVarE}
%         \end{equation}
%     with $\hat{H}$ being the Hamiltonian and $\md^N\vec{r}$ is a short hand for
%     an integral over $\vec{r}_1,\dots,\vec{r}_N$.

\section{SETUP}
\label{sec:setup}
\section{RESULTS}
\label{sec:results}
\section{DISCUSSION}
\label{sec:discussion}
\section{CONCLUSION}
\label{sec:conclusion}

\begin{thebibliography}{}
    \bibitem{GriffQuan}
        David J. Griffiths Chapters 2, 4 and 7,
        \textit{Introduction to Quantum Mechanics Second Edition},
        Pearson, 2005, ISBN 0-13-111892-7.
    \bibitem{basicMB}
        Morten Hjort-Jensen,
        \textit{Computational Physics: Hartree-Fock methods and introduction to Many-Body Theory.} \\
        \url{https://www.github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/pub/basicMB/pdf}, 2017
    \bibitem{vmc}
        Morten Hjort-Jensen,
        \textit{Computational Physics: Variational Monte Carlo methods.} \\
        \url{https://www.github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/pub/vmc/pdf}, 2017
    \bibitem{taut}
        M. Taut, 
        \textit{Two Electrons in an External Oscillator Potential; Particular analytic solutions of a Coulomb Correlation Problem},
        Physical Review A 48, 3561, 1993.
    \bibitem{NeOr}
        Negele and Orland,
        \textit{Quantum Many-Particle Systems},
        Addison-Wesley.
    \bibitem{FeWa}
        Fetter and Walecka,
        \textit{Quantum Theory of Many-Particle Systems},
        Mcgraw-Hill, 1971.
    \bibitem{DiVNe}
        Dickhoss and Van Neck,
        \textit{Many-Body Theory Exposed},
        World Scientific, 2006
\end{thebibliography}

\end{document}
